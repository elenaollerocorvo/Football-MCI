
        "================================================================================\n",
        "          FOOTBALL TOUCH DETECTION PIPELINE - TECHNICAL DOCUMENTATION\n",
        "================================================================================\n",
        "\n",
        "1. MY_LABELING_CODE.PY (GUI LABELING TOOL)\n",
        "--------------------------------------------------------------------------------\n",
        "- Purpose: Graphical tool (PyQt6) for labeling football video/audio.\n",
        "- Functionalities:\n",
        "    * FirstWindow: Project setup, class selection (RightF, LeftF, RightT, LeftT, Chest, Other).\n",
        "    * SecondWindow: Media player, class buttons with shortcuts (Ctrl+1, etc.), timeline.\n",
        "- Output: JSON files per video containing touch frames and timestamps.\n",
        "- JSON Structure: {\"classes\": [...], \"video_lenght_frame\": 1800, \"button_presses\": \"['RightF']: 120; ...\"}\n",
        "\n",
        "2. OBJECT_EXTRACTION.PY (YOLO FEATURE EXTRACTION)\n",
        "--------------------------------------------------------------------------------\n",
        "- Models: YOLOv8m-pose (17 keypoints) and YOLOv8x (ball/person detection).\n",
        "- Features calculated per frame:\n",
        "    * 5 Distances: Ball to Right Foot, Left Foot, Right Thigh, Left Thigh, and Chest.\n",
        "    * 1 Height Ratio: (Person Bounding Box Height) / (Ball Bounding Box Height).\n",
        "- Tracking: Follows the \"active ball\" interacting with the player.\n",
        "- Output: CSV matrix (e.g., New_data_Session25.csv) with 14 columns.\n",
        "- Note: Uses '820' as a constant for missing/undetected data.\n",
        "\n",
        "3. COMBINE_CSV.PY (DATASET MERGING)\n",
        "--------------------------------------------------------------------------------\n",
        "- Purpose: Merges multiple session CSVs into 'combined_file_V5.csv'.\n",
        "- Logic: Adjusts video_ids to be unique and continuous across all sessions.\n",
        "\n",
        "4. DATA_PREPARATION.PY (PRE-PROCESSING)\n",
        "--------------------------------------------------------------------------------\n",
        "- Steps:\n",
        "    * Interpolation: Fills '820' gaps with linear interpolation for better continuity.\n",
        "    * Class Reduction: Merges (RightF, LeftF, RightT, LeftT) into 'Legs'.\n",
        "    * Class Division: Splits 'Other' into 'Other_found' and 'Other_not_found'.\n",
        "    * Normalization: Scaler (0 to 1) for distances and ratios.\n",
        "    * Sliding Windows: Sequences of 50 frames to capture temporal context.\n",
        "    * Balancing: Undersampling to match the minority class (Chest).\n",
        "\n",
        "5. NETWORK_DESIGN.PY (DEEP LEARNING MODEL)\n",
        "--------------------------------------------------------------------------------\n",
        "- Architecture: Hybrid CNN-LSTM.\n",
        "- Layers: Dense (128) -> Dense (64) -> Conv1D (64, kernel 21) -> LSTM (24) -> Dense (64) -> Output (4).\n",
        "- Training: EarlyStopping (patience 10), Adam (0.001), Categorical Crossentropy.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_football_model(input_shape=(50, 6)):\n",
        "    \"\"\"\n",
        "    Architecture designed to process 50-frame sequences with 6 features each.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # 1. Feature Extraction\n",
        "        Input(shape=input_shape),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "\n",
        "        # 2. Temporal Pattern Extraction (CNN)\n",
        "        Conv1D(64, kernel_size=21, activation='relu'),\n",
        "\n",
        "        # 3. Temporal Dependencies (LSTM)\n",
        "        LSTM(24, activation='relu'),\n",
        "\n",
        "        # 4. Classification Layers\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(4, activation='sigmoid') # Legs, Chest, Other_F, Other_NF\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['categorical_accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialize and display architecture\n",
        "model = build_football_model()\n",
        "model.summary()\n",
        "\n",
        "\"\"\"\n",
        "6. NETWORK_VALIDATION.PY (EVALUATION)\n",
        "--------------------------------------------------------------------------------\n",
        "- Metrics: Accuracy (~93%), Confusion Matrices.\n",
        "- Specific Evaluation: Frame-by-frame comparison for individual videos.\n",
        "\n",
        "7. SUPPLEMENTARY SCRIPTS\n",
        "--------------------------------------------------------------------------------\n",
        "- parsing_json.py: Cleans raw label JSONs.\n",
        "- Prikaz_mreze.py: Visualizes the architecture diagram (PNG).\n",
        "- Test_for_matrix_creation.py: Debugs YOLO detection on single images.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2AL4ErQjP50F",
        "outputId": "85c75ddd-601c-4d40-b947-4e3d55890778"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m86,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m8,544\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,544</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m107,588\u001b[0m (420.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,588</span> (420.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m107,588\u001b[0m (420.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,588</span> (420.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n6. NETWORK_VALIDATION.PY (EVALUATION)\\n--------------------------------------------------------------------------------\\n- Metrics: Accuracy (~93%), Confusion Matrices.\\n- Specific Evaluation: Frame-by-frame comparison for individual videos.\\n\\n7. SUPPLEMENTARY SCRIPTS\\n--------------------------------------------------------------------------------\\n- parsing_json.py: Cleans raw label JSONs.\\n- Prikaz_mreze.py: Visualizes the architecture diagram (PNG).\\n- Test_for_matrix_creation.py: Debugs YOLO detection on single images.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}
